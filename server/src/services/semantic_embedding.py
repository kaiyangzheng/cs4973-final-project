from sentence_transformers import SentenceTransformer
import numpy as np
from typing import Union, List

# Initialize the model (this will be done once when the module is imported)
try:
    model = SentenceTransformer("all-MiniLM-L6-v2")
    print("Semantic embedding model loaded successfully")
except Exception as e:
    print(f"Error loading semantic embedding model: {str(e)}")
    model = None

def get_semantic_embedding(text: Union[str, List[str]]) -> np.ndarray:
    """
    Generate semantic embeddings for text using a pre-trained sentence-transformers model.
    
    Args:
        text: Text string or list of strings to embed
        
    Returns:
        numpy array of embeddings
    """
    try:
        if model is None:
            raise ValueError("Semantic embedding model not initialized")
            
        # Ensure text is not empty
        if not text:
            print("Warning: Empty text provided for embedding")
            # Return a zero vector with the correct dimensions (384 for all-MiniLM-L6-v2)
            return np.zeros(384)
            
        # Handle single string vs list of strings
        if isinstance(text, str):
            # Truncate very long texts to avoid memory issues (sentence-transformers works best with sentences/paragraphs)
            # 8000 characters is approximately 1500-2000 words, which should be sufficient for most cases
            if len(text) > 8000:
                print(f"Truncating long text from {len(text)} to 8000 characters for embedding")
                text = text[:8000]
                
        # Generate embeddings
        embeddings = model.encode(text, convert_to_numpy=True)
        
        # If a single string was passed, the result will be a 1D array
        if isinstance(text, str):
            return embeddings
        
        # If a list was passed, return the array of embeddings
        return embeddings
        
    except Exception as e:
        print(f"Error generating semantic embedding: {str(e)}")
        # Return a zero vector with the correct dimensions (384 for all-MiniLM-L6-v2)
        return np.zeros(384)

def get_embedding_dimension() -> int:
    """
    Get the dimension of the embeddings generated by the model.
    
    Returns:
        int: Embedding dimension
    """
    if model is None:
        return 384  # Default dimension for all-MiniLM-L6-v2
    return model.get_sentence_embedding_dimension()

# Simple test to verify the model works
if __name__ == "__main__":
    test_text = "This is a test sentence to verify that the embedding model works."
    embedding = get_semantic_embedding(test_text)
    print(f"Generated embedding with shape: {embedding.shape}")
    print(f"First few values: {embedding[:5]}") 